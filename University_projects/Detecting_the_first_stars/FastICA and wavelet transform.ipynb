{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e23e2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import pywt\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from scipy.stats import pearsonr as pear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd99c454-3190-44e9-ab50-9c42fa5424d6",
   "metadata": {},
   "source": [
    "## Wavelet transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b769bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 128, 128)\n",
      "(342, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "in_path_fg = \"fits_files/\"\n",
    "in_path_cs = \"Boxes/\"\n",
    "\n",
    "output_path = \"Results/\"\n",
    "fname_all = \"test_filename\"\n",
    "\n",
    "fname_foreground = \"fg_all\"\n",
    "fname_cs = \"test\"\n",
    "\n",
    "#1000 hours of noise\n",
    "noise = fits.getdata(r'fits_files/noise_108.000MHz_210.300MHz_SKA_SKA_central_area_EOR0_0128_3.0_1000h_K.fits')\n",
    "#100 hours\n",
    "#noise = fits.getdata('fits_files/Noise_100.fits').T\n",
    "\n",
    "indata_fg = fits.getdata(in_path_fg+fname_foreground+'.fits').T\n",
    "indata_fg = indata_fg + noise\n",
    "\n",
    "indata_cs = fits.getdata(in_path_cs+fname_cs+'.fits')\n",
    "indata_cs = indata_cs/1000\n",
    "sh = indata_cs.shape\n",
    "print(sh)\n",
    "print(indata_cs.shape)\n",
    "no_sl = 342\n",
    "#code for seperating by k-space\n",
    "indata = indata_fg+indata_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836b606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 342)\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Generate sample data\n",
    "#code for fastICA\n",
    "all_cube_in = indata_fg+indata_cs\n",
    "\n",
    "Dim = 128\n",
    "nbrScale = 6\n",
    "\n",
    "#observation\n",
    "all_cube_in = (indata_fg+indata_cs).T\n",
    "print(np.shape(all_cube_in))\n",
    "\n",
    "# Convert to sparse domain\n",
    "WT = np.zeros((Dim,Dim,nbrScale)) # Desired array where we have squashed together the fine/approximation bits\n",
    "WTc_approx = np.zeros((Dim,Dim,nbrScale))\n",
    "WTc_fine = np.zeros((3,Dim,Dim,nbrScale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a5b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_res = np.zeros((128,128,7,342))\n",
    "for i in range(no_sl):\n",
    "    coeffs = pywt.swt2(all_cube_in[:,:,i],'Haar',nbrScale,norm='True')\n",
    "    \n",
    "#Show the approximation and fine detail at each level\n",
    "    for jj in range(0,nbrScale):\n",
    "        WTc_approx[:,:,jj] = coeffs[jj][0]\n",
    "        WTc_fine[:,:,:,jj] = coeffs[jj][1]\n",
    "        space_res[:,:,0,i] = WTc_approx[:,:,0]\n",
    "    \n",
    "    # MERCILESSLY SQUASH THE ARRAYS\n",
    "        WT[:,:,jj] = np.sum(WTc_fine[:,:,:,jj],axis=0)  # These are our wavelet coefficients\n",
    "    \n",
    "\n",
    "    space_res[:,:,1:7,i] = WT[:,:,0:6]\n",
    "\n",
    "    #out = WTc_approx[:,:,0] + np.sum(WT[:,:,0:nbrScale],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cedec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57f406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare k-space combination with the input data\n",
    "#Wave transform\n",
    "#plt.imshow(np.sum(space_res[:,:,0:7,0],axis=2))\n",
    "#plt.colorbar()\n",
    "#input data\n",
    "#plt.figure()\n",
    "#plt.imshow(all_cube_in[:,:,0])\n",
    "#plt.colorbar()\n",
    "#difference\n",
    "#plt.figure()\n",
    "#plt.imshow(all_cube_in[:,:,0] - np.sum(space[:,:,0:7,0],axis=2))\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d9d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 128, 128)\n",
      "(342, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/student2/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_fastica.py:116: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/student2/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_fastica.py:116: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "res = np.zeros((342,128,128,7))\n",
    "rec = np.zeros((342,128,128,7))\n",
    "\n",
    "for i in range(7):\n",
    "    indata = space_res[:,:,i,:].T\n",
    "    sh = indata.shape\n",
    "    print(sh)\n",
    "    X = np.reshape(indata,(sh[0], sh[1]*sh[2]))\n",
    "  \n",
    "    ncomp = 3\n",
    "        \n",
    "    ica1 = FastICA(n_components=ncomp)\n",
    "    model1 = []\n",
    "    S = ica1.fit_transform(X.T)  # Reconstruct signals\n",
    "    A = ica1.mixing_  # Get estimated mixing matrix\n",
    "\n",
    "    model1 = np.reshape(np.matmul(A,S.T),(sh[0], sh[1],sh[2]))\n",
    "    res[:,:,:,i] = indata-model1\n",
    "    #rec[:,:,i,:] =  indata-res[:,:,i,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debfd9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e9734-6f91-4e03-9b5a-0734ad1b66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variance\n",
    "res_2 = np.sum(res[:,:,:,0:8], axis = 3)\n",
    "print(np.shape(res_2))\n",
    "var_21 = np.zeros(no_sl)\n",
    "var_res = np.zeros(no_sl)\n",
    "recover = np.zeros(no_sl)\n",
    "for i in range(no_sl):\n",
    "    var_21[i] = np.var(indata_cs[i,:,:])\n",
    "    var_res[i] = np.var(res_2[i,:,:])\n",
    "    recover[i] = var_res[i] - np.var(noise[i])\n",
    "    \n",
    "       \n",
    "#difference\n",
    "diff = var_21 - var_res\n",
    "diff2 = var_21 - recover\n",
    "\n",
    "x = np.linspace(108,208.3,no_sl)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.title.set_text('Variance')\n",
    "ax.set_xlabel('frequency (MHZ)')\n",
    "im0 = ax.plot(x,var_21,'r',linewidth =3,label='21cmfast')\n",
    "im1 = ax.plot(x,var_res,'g',label='residual')\n",
    "im2 = ax.plot(x,recover, 'b.',markersize=1.5, label = 'recovered_signal')\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "im = ax.plot(x,diff, label =' 21cmsignal - residual')\n",
    "im1 = ax.plot(x,diff2, label = '21cmsignal - recovered')\n",
    "ax.title.set_text('Difference in variance')\n",
    "ax.set_xlabel('frequency(MHZ)')\n",
    "ax.legend()\n",
    "#plt.show()\n",
    "#fig.savefig('images/Variance_noise100.png')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72abb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "resrem = np.sum(res[:,:,:,0:6],axis = 3) \n",
    "#turn into subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(6,12))\n",
    "\n",
    "im1 =axes[0].imshow(resrem[100,:,:] - noise[100,:,:])\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Taking the noise away from the residual')\n",
    "\n",
    "im2 =axes[1].imshow(indata_cs[100,:,:])\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('21cmsignal')\n",
    "\n",
    "im3 =axes[2].imshow(resrem[100])\n",
    "fig.colorbar(im3, ax=axes[2])\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title('Removing the last wavelet transform')\n",
    "\n",
    "#plt.savefig('images/comparing WT with removing the noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b546b0c",
   "metadata": {},
   "source": [
    "## Correlate each WT of 21cm,noise and residual together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import pywt\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from scipy.stats import pearsonr as pear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e85273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path_fg = \"fits_files/\"\n",
    "in_path_cs = \"Boxes/\"\n",
    "\n",
    "output_path = \"Results/\"\n",
    "fname_all = \"test_filename\"\n",
    "\n",
    "fname_foreground = \"fg_all\"\n",
    "fname_cs = \"test\"\n",
    "\n",
    "#1000 hours of noise\n",
    "noise = fits.getdata(r'fits_files/noise_108.000MHz_210.300MHz_SKA_SKA_central_area_EOR0_0128_3.0_1000h_K.fits')\n",
    "#100 hours\n",
    "#noise = fits.getdata('fits_files/Noise_100.fits').T\n",
    "\n",
    "indata_fg = fits.getdata(in_path_fg+fname_foreground+'.fits').T\n",
    "indata_fg = indata_fg + noise\n",
    "\n",
    "indata_cs = fits.getdata(in_path_cs+fname_cs+'.fits')\n",
    "indata_cs = (indata_cs/1000)\n",
    "sh = indata_cs.shape\n",
    "print(sh)\n",
    "print(indata_cs.shape)\n",
    "no_sl = 342\n",
    "#code for seperating by k-space\n",
    "indata = indata_fg+indata_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(noise))\n",
    "plt.imshow(noise[10,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d33f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Generate sample data\n",
    "#code for fastICA\n",
    "all_cube_in = indata_fg+indata_cs\n",
    "\n",
    "Dim = 128\n",
    "nbrScale = 6\n",
    "\n",
    "#observation\n",
    "all_cube_in = (indata_fg+indata_cs).T\n",
    "indata_cs = indata_cs.T\n",
    "noise = noise.T\n",
    "\n",
    "print(np.shape(all_cube_in))\n",
    "\n",
    "# Convert to sparse domain\n",
    "WT = np.zeros((Dim,Dim,nbrScale)) # Desired array where we have squashed together the fine/approximation bits\n",
    "WTc_approx = np.zeros((Dim,Dim,nbrScale))\n",
    "WTc_fine = np.zeros((3,Dim,Dim,nbrScale))\n",
    "#for 21cmsignal\n",
    "# Convert to sparse domain\n",
    "WT_l = np.zeros((Dim,Dim,nbrScale)) # Desired array where we have squashed together the fine/approximation bits\n",
    "WTc_approx_l = np.zeros((Dim,Dim,nbrScale))\n",
    "WTc_fine_l = np.zeros((3,Dim,Dim,nbrScale))\n",
    "#for noise\n",
    "# Convert to sparse domain\n",
    "WT_n = np.zeros((Dim,Dim,nbrScale)) # Desired array where we have squashed together the fine/approximation bits\n",
    "WTc_approx_n = np.zeros((Dim,Dim,nbrScale))\n",
    "WTc_fine_n = np.zeros((3,Dim,Dim,nbrScale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8602bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indata_slices = np.zeros((128,128,7,342))\n",
    "light_slices = np.zeros((128,128,7,342))\n",
    "noise_slices = np.zeros((128,128,7,342))\n",
    "\n",
    "\n",
    "for i in range(no_sl):\n",
    "    # indata coefficients\n",
    "    coeffs = pywt.swt2(all_cube_in[:,:,i],'Haar',nbrScale,norm='True')\n",
    "    # 21cmsignal\n",
    "    coeffs_light = pywt.swt2(indata_cs[:,:,i],'Haar',nbrScale,norm='True')\n",
    "    # noise\n",
    "    coeffs_noise = pywt.swt2(noise[:,:,i],'Haar',nbrScale,norm='True')\n",
    "    \n",
    "#Show the approximation and fine detail at each level\n",
    "    for jj in range(0,nbrScale):\n",
    "        WTc_approx[:,:,jj] = coeffs[jj][0]; WTc_fine[:,:,:,jj] = coeffs[jj][1]\n",
    "    # MERCILESSLY SQUASH THE ARRAYS\n",
    "        WT[:,:,jj] = np.sum(WTc_fine[:,:,:,jj],axis=0)  # These are our wavelet coefficients\n",
    "    \n",
    "    #light\n",
    "        WTc_approx_l[:,:,jj] = coeffs_light[jj][0]; WTc_fine_l[:,:,:,jj] = coeffs_light[jj][1]\n",
    "    \n",
    "    # MERCILESSLY SQUASH THE ARRAYS\n",
    "        WT_l[:,:,jj] = np.sum(WTc_fine_l[:,:,:,jj],axis=0)  # These are our wavelet coefficient\n",
    "\n",
    "    #Noise\n",
    "        WTc_approx_n[:,:,jj] = coeffs_noise[jj][0]; WTc_fine_n[:,:,:,jj] = coeffs_noise[jj][1]\n",
    "        noise_slices[:,:,0,i] = WTc_approx_n[:,:,0]\n",
    "    \n",
    "    # MERCILESSLY SQUASH THE ARRAYS\n",
    "        WT_n[:,:,jj] = np.sum(WTc_fine_n[:,:,:,jj],axis=0)  # These are our wavelet coefficient\n",
    "    \n",
    "    #crude approximation\n",
    "    indata_slices[:,:,0,i] = WTc_approx[:,:,0]\n",
    "    light_slices[:,:,0,i] = WTc_approx_l[:,:,0]\n",
    "    noise_slices[:,:,0,i] = WTc_approx_n[:,:,0]\n",
    "\n",
    "\n",
    "     #finer approximation\n",
    "    indata_slices[:,:,1:7,i] = WT[:,:,0:6]\n",
    "    light_slices[:,:,1:7,i] = WT_l[:,:,0:6]\n",
    "    noise_slices[:,:,1:7,i] = WT_n[:,:,0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros((342,128,128,7))\n",
    "#rec = np.zeros((342,128,128,7))\n",
    "\n",
    "for i in range(7):\n",
    "    indata = indata_slices[:,:,i,:].T\n",
    "    sh = indata.shape\n",
    "    print(sh)\n",
    "    X = np.reshape(indata,(sh[0], sh[1]*sh[2]))\n",
    "  \n",
    "    ncomp = 3\n",
    "        \n",
    "    ica1 = FastICA(n_components=ncomp)\n",
    "    model1 = []\n",
    "    S = ica1.fit_transform(X.T)  # Reconstruct signals\n",
    "    A = ica1.mixing_  # Get estimated mixing matrix\n",
    "\n",
    "    model1 = np.reshape(np.matmul(A,S.T),(sh[0], sh[1],sh[2]))\n",
    "    res[:,:,:,i] = indata-model1\n",
    "    #rec[:,:,i,:] =  indata-res[:,:,i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so I have three WT: res, light_slices and, noise_slices\n",
    "# make sure the shapes are the same for each of the three WT\n",
    "light_slices = light_slices.T\n",
    "noise_slices = noise_slices.T\n",
    "print('Residual has the shape   =',np.shape(res))\n",
    "print('21cmsignal has the shape =',np.shape(light_slices))\n",
    "print('Noise has the shape      =',np.shape(noise_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55adb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a slice for each WT\n",
    "#plt.figure()\n",
    "#plt.imshow(res[100,:,:,4])\n",
    "#plt.figure()\n",
    "#plt.imshow(light_slices[100,4,:,:])\n",
    "#plt.figure()\n",
    "#plt.imshow(noise_slices[100,4,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9fe9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show 3 columns and 8 rows of the WT slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and subplots\n",
    "fig, axs = plt.subplots(4, 3, figsize=(8,6), gridspec_kw ={'hspace':0.25, 'wspace':0.0})\n",
    "\n",
    "for col in range(4):\n",
    "    #plot subplots\n",
    "    #residual\n",
    "    axs[col, 0].imshow(res[100,:,:,col])\n",
    "    axs[col, 0].axis('off')\n",
    "    #light\n",
    "    axs[col, 1].imshow(light_slices[100,col,:,:])\n",
    "    axs[col, 1].axis('off')\n",
    "    #noise\n",
    "    axs[col, 2].imshow(noise_slices[100,col,:,:])\n",
    "    axs[col, 2].axis('off')\n",
    "    \n",
    "    axs[col, 0].text( -10, -10, f'Residual, W = {col+1}')\n",
    "    \n",
    "    axs[col, 1].text( -30, -10, f'Cosmological, W = {col+1}')\n",
    "\n",
    "    axs[col, 2].text( 5, -10, f'Noise, W = {col+1}')\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.figure()\n",
    "#plt.imshow(np.sum(noise_slices[10,0:8,:,:], axis = 0))\n",
    "#plt.figure()\n",
    "#plt.imshow(noise[:,:,10].T)\n",
    "plt.savefig('Submit/comparing_WT_of_res_21cm_noise.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate the 21cmsignal and noise with the residual then, plot a graph of correlation.\n",
    "corr_res_21 = np.zeros((7,342))\n",
    "corr_res_noise = np.zeros((7,342))\n",
    "for i in range(7):\n",
    "    for m in range(342):\n",
    "        residual = res[m,:,:,i]\n",
    "        # you have to transpose the 21cmsignal and noise to get the correct orientation\n",
    "        light = light_slices[m,i,:,:]\n",
    "        noise = noise_slices[m,i,:,:]\n",
    "        corr_res_21[i,m] = pear(residual.flatten(), light.flatten())[0]\n",
    "        corr_res_noise[i,m] = pear(residual.flatten(), noise.flatten())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_res_21[:,0])\n",
    "print(corr_res_noise[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see the data from 21cmsignal is the same as the combine WT\n",
    "#plt.imshow(np.sum(light_slices[0,0:7,:,:],axis =0))\n",
    "#plt.colorbar()\n",
    "#plt.figure()\n",
    "#plt.imshow(indata_cs[:,:,0].T)\n",
    "#plt.colorbar()\n",
    "#plt.figure()\n",
    "#plt.imshow(indata_cs[:,:,0].T - np.sum(light_slices[0,0:7,:,:],axis =0))\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2c092",
   "metadata": {},
   "source": [
    "### Important note: Using FastICA to get the residual results, Transposed the images. Need to make sure fast21cm and the noise is also transposed when  comparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,8)\n",
    "plt.figure()\n",
    "plt.plot(x,corr_res_21[:,100],'.--', label = 'Cosmological signal')\n",
    "plt.plot(x,corr_res_noise[:,100],'.--', label = 'Noise')\n",
    "plt.grid(True, linestyle= '--', alpha = 0.5)\n",
    "plt.xlabel('Wavelet number')\n",
    "plt.ylabel('Correlation')\n",
    "plt.title('Correlation with the residual Wavelets ', fontsize=12)\n",
    "plt.legend()\n",
    "#plt.savefig('images/correlation_with_residual_100slice.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f9fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average\n",
    "mean_res_21 = np.zeros(7)\n",
    "mean_res_noise = np.zeros(7)\n",
    "for i in range(7):\n",
    "    mean_res_21[i] = np.mean(corr_res_21[i,:])\n",
    "    mean_res_noise[i] = np.mean(corr_res_noise[i,:])\n",
    "print(np.shape(corr_res_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,8)\n",
    "plt.rcParams.update({'font.size' : 10})\n",
    "plt.figure(figsize =(6,4))\n",
    "plt.plot(x,mean_res_21,'.--', label = 'Cosmological signal')\n",
    "plt.plot(x,mean_res_noise,'.--', label = 'Noise')\n",
    "plt.grid(True, linestyle= '--', alpha = 0.5)\n",
    "plt.xlabel('Wavelet number.')\n",
    "plt.ylabel('Average correlation')\n",
    "#plt.title('Average correlation with the residual wavelets', fontsize=12)\n",
    "plt.legend()\n",
    "plt.savefig('Submit/correlation_with_residual_WT_average.png')\n",
    "print(mean_res_21)\n",
    "print(mean_res_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f80c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.sum(light_slices[150,0:7,:,:],axis=0)\n",
    "actual = np.sum(res[150,:,:,0:7],axis=2)\n",
    "plt.imshow(test)\n",
    "plt.figure()\n",
    "plt.imshow(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180895fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the best slice by taking the average of the WT\n",
    "all_res_slices = np.zeros(342)\n",
    "all_noise_slices = np.zeros(342)\n",
    "\n",
    "residual = np.sum(res[:,:,:,0:8], axis = 3)\n",
    "light = np.sum(light_slices[:,0:8,:,:], axis = 1)\n",
    "noise = np.sum(noise_slices[:,0:8,:,:], axis = 1)\n",
    "#print shape size\n",
    "print(np.shape(residual))\n",
    "print(np.shape(light))\n",
    "print(np.shape(noise))\n",
    "\n",
    "\n",
    "for m in range(342):\n",
    "        residua = residual[m,:,:]\n",
    "        ligh = light[m,:,:]\n",
    "        nois = noise[m,:,:]\n",
    "        all_res_slices[m] = pear(residua.flatten(), ligh.flatten())[0]\n",
    "        all_noise_slices[m] = pear(residua.flatten(), nois.flatten())[0]\n",
    "\n",
    "\n",
    "# print max slice correlation\n",
    "print('Max slice = ',np.argmax(all_res_slices))\n",
    "print('Max slice corr value = ',all_res_slices[135])\n",
    "#print min slice correlation\n",
    "print('Min slices = ',np.argmin(all_res_slices))\n",
    "print('Min value corr value = ',all_res_slices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_slice = np.sum(res[135,:,:,0:8],axis = 2)\n",
    "worst_slice = np.sum(res[0,:,:,0:8],axis = 2)\n",
    "plt.rcParams.update({'font.size' : 10})\n",
    "\n",
    "\n",
    "\n",
    "#enhance best slice image, bright spots brighter, dark spots darker\n",
    "enhanced = np.zeros((128,128))\n",
    "enhanced_worst = np.zeros((128,128))\n",
    "\n",
    "for i in range(128):\n",
    "    for m in range(128):\n",
    "        best = best_slice[i,m]\n",
    "        worst = worst_slice[i,m]\n",
    "        if best > 0.0:\n",
    "            enhanced[i,m] = best*10\n",
    "        if worst > 0.0:\n",
    "            enhanced_worst[i,m] = worst*10\n",
    "\n",
    "\n",
    "            \n",
    "# create figure and subplots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(8,6))\n",
    "\n",
    "print(np.shape(indata_cs))\n",
    "\n",
    "axs[0,0].imshow(best_slice); axs[0,0].axis('off'); axs[0,0].set_title('Best residual, corr = 0.70')\n",
    "\n",
    "axs[0,1].imshow(enhanced); axs[0,1].axis('off'); axs[0,1].set_title('Enhanced residual')\n",
    "\n",
    "axs[0,2].imshow(np.sum(light_slices[135,0:8,:,:], axis = 0)); axs[0,2].axis('off')\n",
    "axs[0,2].set_title('Cosmological signal')\n",
    "\n",
    "\n",
    "axs[1,0].imshow(worst_slice); axs[1,0].axis('off'); axs[1,0].set_title('Worst residual, corr = 0.19')\n",
    "\n",
    "axs[1,1].imshow(enhanced_worst); axs[1,1].axis('off'); axs[1,1].set_title('Enhanced residual')\n",
    "\n",
    "axs[1,2].imshow(np.sum(light_slices[0,0:8,:,:], axis = 0)); axs[1,2].axis('off')\n",
    "axs[1,2].set_title('Cosmological signal')\n",
    "\n",
    "plt.savefig('Submit/best_and_worst_residuals')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfeadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = np.arange(108,210.6,0.3)\n",
    "result_forward = np.zeros((342,7))\n",
    "result_backwards = np.zeros((342,7))\n",
    "for m in range(7):\n",
    "    k = 7 - m\n",
    "    for i in range(no_sl):\n",
    "        light = np.sum(light_slices[i,0:7,:,:],axis=0)\n",
    "        residual = np.sum(res[i,:,:,m:7],axis=2)\n",
    "        result_forward[i,m] = pear(light.flatten(),residual.flatten())[0]\n",
    "        resi = np.sum(res[i,:,:,0:k],axis=2)\n",
    "        result_backwards[i,m] = pear(light.flatten(),resi.flatten())[0]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20979f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize =(14,5))\n",
    "for m in range(7):\n",
    "    axes[0].plot(freq[::4],result_forward[::4,m], label = \"No. of slices removed = \"+str(m))\n",
    "    axes[0].legend(fontsize = 7)\n",
    "    axes[0].grid()\n",
    "    axes[0].set_xlabel('Frequency (Hz)')\n",
    "    axes[0].set_ylabel('Correlation')\n",
    "    axes[0].set_ylim(0.1,0.8)\n",
    "    axes[0].set_title('Correlation with 21cmsignal, remove from largest k-space from WT')\n",
    "\n",
    "\n",
    "    axes[1].plot(freq[::4], result_backwards[::4,m], label = \"No. of slices removed = \"+str(m))\n",
    "    axes[1].legend()\n",
    "    axes[1].grid()\n",
    "    axes[1].set_xlabel('Frequency (Hz)')\n",
    "    axes[1].set_ylabel('Correlation')\n",
    "    axes[1].set_ylim(-0.12,0.85)\n",
    "    axes[1].legend(fontsize = 7)\n",
    "    axes[1].set_title('Correlation with 21cmsignal, remove from smallest k-space from WT')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/corr 21cmsignal WT k-space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96081c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.rcParams.update({'font.size' : 10})\n",
    "\n",
    "for m in range(7):\n",
    "    plt.plot(freq[::4],result_forward[::4,m], label = \"No. of slices removed = \"+str(m))\n",
    "    plt.legend(fontsize = 7)\n",
    "plt.grid(True, linestyle= '--', alpha = 0.5)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Correlation')\n",
    "plt.ylim(0.1,0.8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Submit/Residual_corr_21_remove_smallest_k-space.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9ca50-f98c-4626-a149-1d7bc1249b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.rcParams.update({'font.size' : 8})\n",
    "\n",
    "for m in range(7):\n",
    "    plt.plot(freq[::4],result_backwards[::4,m], label = \"Wavelets removed = \"+str(m))\n",
    "    plt.legend()\n",
    "plt.grid(True, linestyle= '--', alpha = 0.5)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Correlation')\n",
    "plt.ylim(-0.12,0.85)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Submit/Residual_corr_21_remove_largest_k-space.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
